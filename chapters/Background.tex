%background.TeX
In addition to the Monte Carlo simulation, a data driven method is used to estimate a significant portion of background that simulation alone is not sufficient to measure. Tau leptons decay hadronically about 65\% of the time forming intermediate mesons. The clusters of hadrons that these decays produce are very similar to Quantum Chromodynamic (QCD) processes. These QCD events effectively fake the hadronic $\tau$ signature for the $a$ decay. 

In order to conduct the data driven method, a proportionality is made to extract the jet faking tau background. Generally,this proportion is constructed using an orthogonal region to the statistical hypthesis test (the test is conducted in the signal region). For example this could be sign inversion on the lepton pair used in the final state. In this orthogonal region and in the signal region, tight and loose identification criteria is made to extrapolate the scale factor. One of the critical assumptions for this method to hold is that the shape of the distribution doesn't change much by the tight to loose regions. Therefore using the orthogonal reigons --- tight and loose --- along with the loose signal region one can extrapolate the number of events in the tight signal region. Due to the four regions, the method is also referred to as the "ABCD" method. 


\subsection{Brief Outline of the Fake Rate Method}
The general outline to measure the fake rate is as follows:
The fake rate function in same sign (SS) region is \textit{known}
Events passing loose identification in opposite sign (OS)region is \textit{known} 
Events passing signal region is \textit{unknown}
 Prompt MC is subtracted from data, which is motivated by estimating the true jet faking taus background (non-prompt taus). If MC is matched to prompt then it is unlikely a jet faking tau – so they are removed 
\[f_r(pt)=\frac{\text{Data Events S.S. Tight - Prompt MC Background}}{\text{Data Events S.S. Loose - Prompt MC Background}}\] 

After the measurement is made for each leg, then apply the fake rate as a weight to the Opposite Sign "tight" region (the signal region) for one leg at a time
The fake rate function is parametrized in lepton candidate transverse momentum

\subsection{Measurement of the Fake Rate}
To measure the fake rate multiple categories are considered. As outlined in the standard model Higgs decays to tau leptons analysis and it's supporting document on fake rate measurements ~\cite{AN16355} , several regions are used to determine the fake rate. The separate ``enriched" background regions are considered 
\begin{itemize}
	\item QCD multijet (large majority of jet→ \tauh fake events in the \tauh \tauh final state)
	\item W+jets (mostly in the e\tauh and µ\tauh final states)
	\item tt events with fully-hadronic or semi-leptonic decays (mostly in the VBF category)
	\item diboson events with fully-hadronic or semi-leptonic decays.
\end{itemize} 

These are then measured as a function of $p_T$ of the object and split into subcategories depending on the decay mode.  

In the QCD multijet region, there is no way to estimate it with pure MC simulation. Therefore, in order to estimate the QCD contribution all MC simulation events are subtracted before the measurements. Then the remaining fake rate measurement in the determination region is assumed to be from QCD.

The W+Jets region, similarly all MC is subtracted except for the W+Jets simulation. Note that QCD contamination is minimal because of the dominance of the W boson resonance. 

In the $t\bar{t}$ region it is the same as the W+Jets regions, except the subtraction is $ttbar$; however, there is also an isolation region that is used because the fake rate for this process is expected to be very small and actually calculable using MC, so in addition to the genuine $t\bar{t}$ events, the fraction of jets faking hadronic taus are also included in the subtraction. 





To parameterize the fake rates as a smooth function in $p_T$, a line is fitted to each distribution. 
In addition to measuring the rate for each ``enriched" background region, they are further split by final state or lepton candidate composition. 

W+jets with no jets and one jet, QCD multi-jet with no jets, one jet, and more jets, and $t\bar{t}$ make up the total number of background categories that are measured. Only plots pertaining to the $\mu\mu e \tau$ and $\mu\mu \mu \tau$ channels are created. 

At high hadronic tau $p_T$ (greater than 100\GeV), negative fake rates are possible because of low stats and the linear fit model extrapolation, so if the candidate tau has a $p_T$ of greater than 100\GeV then the rate at 100\GeV is applied. 

Fake factor measurements for the $\mu\mu\mu\tau$ channel in the QCD 0jet region for 2017 is included in figure \ref{fig:fit_raw_mt_0jet_qcd}. 

The rest of the regions are included in the Appendix \ref{app:ffmeas}.




\begin{figure}[ht!b]
\centering
%\includegraphics[width=0.31\textwidth]{Figures/FF/plots_mt_2016/fit_rawFF_mt_qcd_0jet.pdf}
\includegraphics[width=0.85\textwidth]{Figures/FF/plots_mt_2017/fit_rawFF_mt_qcd_0jet.pdf}\\
%\includegraphics[width=0.31\textwidth]{Figures/FF/plots_mt_2018/fit_rawFF_mt_qcd_0jet.pdf}\\
\caption{\label{fig:fit_raw_mt_0jet_qcd} Fake factors determined in the QCD multijet determination region with 0 jet in the $\Pgm\tauh$ final state in 2016 (left), 2017 (center), and 2018 (right). They are fitted with linear functions as a function of the $\tauh$ $\pt$. The green and purple lines indicate the shape systematics obtained by uncorrelating the uncertainties in the two fit parameters returned by the fit.  }
\end{figure}





\clearpage

\subsection{Application of the Fake Rate Method}

After the jet faking tau rate is measured, it is then applied to events that are identified as loose. Since the final state involves two tau leptons, this procedure is applied to each tau lepton in the final state thus requiring application of the fake rate to four different possibilities. Each lepton ``leg" may be identify as loose or equivalently, failing the tight identification. The fake rate is then applied depending on the identification for each leg and in the case the event fails both legs then a minus sign is included to avoid the case of double counting. 
\begin{itemize}
\item{The final weight is then 
applied depending on the 
pass and fail criteria of each 
lepton candidate}
\item{If event fails id for leg 1:\[f_1(pt)=\frac{f_{r_1}(pt)}{1-f_{r_1}(pt)}\]}
\item{If event fails id for leg 2:\[f_2(pt)=\frac{f_{r_2}(pt)}{1-f_{r_2}(pt)}\]}
\item{If event fails id for both:\[f_{12}(pt)=-\frac{f_{r_1}(pt)}{1-f_{r_1}(pt)}\cdot\frac{f_{r_2}(pt)}{1-f_{r_2}(pt)}\]}
\end{itemize}


To illustrate the different regions please consider the diagram outlining the different regions in the ``ABCD" method \ref{fig:fakefactor_reg}. 
\begin{figure}[ht!b]
  \includegraphics[width=0.9\textwidth]{"Figures/fakefactor_diagram.pdf"}
    \caption{\label{fig:fakefactor_reg} Diagram depicting the measurement and application regions, this ``ABCD'' method is multiplied by each of the $\tau$ leptons in the final sate}
\end{figure}

This fake factor methodology has been used by other analyses such as the standard model Higgs measurement with an associated Z boson ~\cite{CMS-PAS-HIG-19-010} . 

For a closure test, the same criteria are applied to the selection of the tight same sign region. The vast majority of the background should be jets faking taus in that case. Indeed it is shown in figure \ref{fig:fakefactor_validation}.
  
\begin{figure}[ht!b]
  \includegraphics[width=0.65\textwidth]{"Figures/outplots_2016_smFF_mmmt_Nominal/AMass_blinded_mmmt_FF_SS_validation.png"}
    \caption{\label{fig:fakefactor_validation} Validation of the fake factor method, fake factors are applied to the same sign tight region}
\end{figure}
